{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e01985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import chromadb\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbd64c",
   "metadata": {},
   "source": [
    "> Download Ollama: https://ollama.com/download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80eec70",
   "metadata": {},
   "source": [
    "# Extract text from pdf and store them as chunks in vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5dbd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "file = \"lab_in_the_loop.pdf\"\n",
    "text = extract_text(file)\n",
    "\n",
    "# convert text into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64,\n",
    "                                          separators=[\"\\n\\nTable\",\"\\nRow\", \"\\n\"])\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# create embeddings from the chunks\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "# save chunks in the vectorDB\n",
    "vector_store = Chroma(collection_name=\"research_papers\",\n",
    "                      embedding_function=embeddings,\n",
    "                      persist_directory=\"./chroma_langchain_db\")\n",
    "# index chunks\n",
    "index = vector_store.aadd_texts(texts=chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a1218e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the chunks from the vector_store\n",
    "all_docs = vector_store.get()\n",
    "all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07928e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import faiss\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# get embedding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fb5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b65af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511620a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e413ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10564fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a7285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca79200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb149879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je aime le programmation.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-06-12T14:24:26.3421796Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6606706800, 'load_duration': 3382393100, 'prompt_eval_count': 45, 'prompt_eval_duration': 2552058300, 'eval_count': 7, 'eval_duration': 660035500, 'model_name': 'llama3.2'}, id='run--08abae3e-7188-4dfb-a575-ad7313c9d90f-0', usage_metadata={'input_tokens': 45, 'output_tokens': 7, 'total_tokens': 52})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf90ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
